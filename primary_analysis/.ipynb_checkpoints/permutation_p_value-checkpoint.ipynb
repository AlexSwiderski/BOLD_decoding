{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c33ade",
   "metadata": {},
   "source": [
    "The first two cells provide an example of how we shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9bb98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the semantic-model correlation matrix from GloVe_sim.csv\n",
    "semantic_model_df = pd.read_csv('GloVe_sim.csv')\n",
    "\n",
    "# Get the number of words\n",
    "num_words = len(semantic_model_df.columns) - 1  # Assuming the first column is not a word but an identifier like 'term'\n",
    "\n",
    "# Create a vector of word indices and shuffle it\n",
    "word_indices = np.arange(num_words)\n",
    "np.random.shuffle(word_indices)\n",
    "\n",
    "# Reorder the rows and columns of the semantic-model correlation matrix\n",
    "shuffled_semantic_model_df = semantic_model_df.iloc[:, 1:].iloc[word_indices, word_indices]\n",
    "\n",
    "# Add the 'term' column back to maintain the structure\n",
    "shuffled_semantic_model_df.insert(0, 'term', semantic_model_df['term'].iloc[word_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9004fef",
   "metadata": {},
   "source": [
    "Now we create a big loop to do estimate our permutation p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4bcf8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoding_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18416\\1796896735.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# Append results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     decoding_results.append({\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;34m'word1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mword1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;34m'word2'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mword2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decoding_results' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Make sure semantic model DataFrame is called semantic_model_df!!!\n",
    "# Load the original neural and word2vec similarity matrices\n",
    "word2vec_sim_df = pd.read_csv('GloVe_sim.csv')\n",
    "neural_sim_df = pd.read_csv('p1_sim.csv')\n",
    "\n",
    "#uncessesarry variable name change for variable, but correct coding \n",
    "neural_sim_df_reordered = neural_sim_df\n",
    "\n",
    "\n",
    "# List of words (excluding the 'term' column)\n",
    "words = word2vec_sim_df.columns[1:]\n",
    "\n",
    "# Initialize a list or DataFrame to store results\n",
    "decoding_accuracies = []\n",
    "\n",
    "# Number of iterations for the permutation test\n",
    "num_iterations = 10\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    # Shuffle the semantic-model correlation matrix\n",
    "    word_indices = np.arange(len(semantic_model_df.columns) - 1)\n",
    "    np.random.shuffle(word_indices)\n",
    "    shuffled_semantic_model_df = semantic_model_df.iloc[:, 1:].iloc[word_indices, word_indices]\n",
    "    shuffled_semantic_model_df.insert(0, 'term', semantic_model_df['term'].iloc[word_indices])\n",
    "\n",
    "    # Run your decoding analysis with the shuffled_semantic_model_df\n",
    "   # Iterate over all unique pairs of words\n",
    "for word1, word2 in combinations(words, 2):\n",
    "    # Extract vectors\n",
    "    word1_neural_vector = neural_sim_df_reordered[word1]\n",
    "    word2_neural_vector = neural_sim_df_reordered[word2]\n",
    "    word1_semantic_vector = word2vec_sim_df[word1]\n",
    "    word2_semantic_vector = word2vec_sim_df[word2]\n",
    "\n",
    "    # Remove indices with perfect correlations\n",
    "    perfect_corr_indices = (word1_neural_vector == 1.0) | (word2_neural_vector == 1.0) | \\\n",
    "                           (word1_semantic_vector == 1.0) | (word2_semantic_vector == 1.0)\n",
    "    word1_neural_vector_filtered = word1_neural_vector[~perfect_corr_indices]\n",
    "    word2_neural_vector_filtered = word2_neural_vector[~perfect_corr_indices]\n",
    "    word1_semantic_vector_filtered = word1_semantic_vector[~perfect_corr_indices]\n",
    "    word2_semantic_vector_filtered = word2_semantic_vector[~perfect_corr_indices]\n",
    "\n",
    "    # Calculate correlations\n",
    "    corr_word1_neural_semantic = pearsonr(word1_neural_vector_filtered, word1_semantic_vector_filtered)[0]\n",
    "    corr_word1_neural_word2_semantic = pearsonr(word1_neural_vector_filtered, word2_semantic_vector_filtered)[0]\n",
    "    corr_word2_neural_semantic = pearsonr(word2_neural_vector_filtered, word2_semantic_vector_filtered)[0]\n",
    "    corr_word2_neural_word1_semantic = pearsonr(word2_neural_vector_filtered, word1_semantic_vector_filtered)[0]\n",
    "\n",
    "    # Check decoding accuracy\n",
    "    decode_accuracy_word1 = corr_word1_neural_semantic > corr_word1_neural_word2_semantic\n",
    "    decode_accuracy_word2 = corr_word2_neural_semantic > corr_word2_neural_word1_semantic\n",
    "\n",
    "    # Append results\n",
    "    decoding_results.append({\n",
    "        'word1': word1,\n",
    "        'word2': word2,\n",
    "        'corr_word1_neural_semantic': corr_word1_neural_semantic,\n",
    "        'corr_word1_neural_word2_semantic': corr_word1_neural_word2_semantic,\n",
    "        'corr_word2_neural_semantic': corr_word2_neural_semantic,\n",
    "        'corr_word2_neural_word1_semantic': corr_word2_neural_word1_semantic,\n",
    "        'decode_accuracy_word1': decode_accuracy_word1,\n",
    "        'decode_accuracy_word2': decode_accuracy_word2\n",
    "    })\n",
    "    \n",
    "    # For example, you would calculate the decoding accuracy for this shuffled matrix\n",
    "    total_accuracy = (decoding_results_df['decode_accuracy_word1'].sum() + \n",
    "                  decoding_results_df['decode_accuracy_word2'].sum())\n",
    "    decoding_accuracy = total_accuracy / (2 * len(decoding_results_df))\n",
    "    \n",
    "    # Append the result to the list\n",
    "    decoding_accuracies.append(decoding_accuracy)\n",
    "\n",
    "# If you used a list, convert it to a DataFrame\n",
    "decoding_accuracies_df = pd.DataFrame(decoding_accuracies, columns=['Decoding Accuracy'])\n",
    "\n",
    "# Now decoding_accuracies_df contains the decoding accuracies for all 10,000 iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017338d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
