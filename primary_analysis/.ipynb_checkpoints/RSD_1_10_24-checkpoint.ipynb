{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126a9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48dfcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matrices(neural_path, semantic_path):\n",
    "    \"\"\"Load the neural and semantic correlation matrices.\"\"\"\n",
    "    neural_matrix = pd.read_csv(neural_path)\n",
    "    semantic_matrix = pd.read_csv(semantic_path)\n",
    "    return neural_matrix, semantic_matrix\n",
    "\n",
    "def calculate_correct_correlation_match(reduced_neural, reduced_semantic, word_1, word_2):\n",
    "    \"\"\"\n",
    "    Calculate the correct correlation match for a given pair of words.\n",
    "    Args:\n",
    "    reduced_neural (DataFrame): The reduced neural-activity-correlation matrix.\n",
    "    reduced_semantic (DataFrame): The reduced semantic-model-correlation matrix.\n",
    "    word_1, word_2 (str): The words to be matched.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Correlation for each word with both semantic codes.\n",
    "    \"\"\"\n",
    "    # Extract similarity codes for the words\n",
    "    neural_code_1 = reduced_neural[word_1]\n",
    "    neural_code_2 = reduced_neural[word_2]\n",
    "    semantic_code_1 = reduced_semantic[word_1]\n",
    "    semantic_code_2 = reduced_semantic[word_2]\n",
    "\n",
    "    # Calculate correlations for each word with both semantic codes\n",
    "    correlation_1_with_1 = pearsonr(neural_code_1, semantic_code_1)[0]  # word_1 neural with word_1 semantic\n",
    "    correlation_1_with_2 = pearsonr(neural_code_1, semantic_code_2)[0]  # word_1 neural with word_2 semantic\n",
    "    correlation_2_with_1 = pearsonr(neural_code_2, semantic_code_1)[0]  # word_2 neural with word_1 semantic\n",
    "    correlation_2_with_2 = pearsonr(neural_code_2, semantic_code_2)[0]  # word_2 neural with word_2 semantic\n",
    "\n",
    "    return (correlation_1_with_1, correlation_1_with_2), (correlation_2_with_1, correlation_2_with_2)\n",
    "\n",
    "def is_decoding_correct(correlations):\n",
    "    \"\"\"Determine if the decoding is correct.\"\"\"\n",
    "    (corr_1_with_1, corr_1_with_2), (corr_2_with_1, corr_2_with_2) = correlations\n",
    "    return int(corr_1_with_1 > corr_1_with_2 and corr_2_with_2 > corr_2_with_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b41215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrices\n",
    "neural_matrix, semantic_matrix = load_matrices('p3_bold_sim.csv', 'wordnetRDM_noheader.csv')\n",
    "\n",
    "# Generate all word pairs\n",
    "terms = neural_matrix['term'].tolist()\n",
    "word_pairs = list(combinations(terms, 2))\n",
    "\n",
    "# Initialize results list\n",
    "decoding_results = []\n",
    "\n",
    "# Loop through each word pair and perform decoding\n",
    "for pair in word_pairs:\n",
    "    # Reduce the matrices for the current pair\n",
    "    reduced_neural = neural_matrix.drop(columns=pair, index=pair, errors='ignore')\n",
    "    reduced_semantic = semantic_matrix.drop(columns=pair, index=pair, errors='ignore')\n",
    "\n",
    "    # Calculate the correct correlations for the current pair\n",
    "    correct_correlation_match = calculate_correct_correlation_match(reduced_neural, reduced_semantic, *pair)\n",
    "\n",
    "    # Store the results for the current pair\n",
    "    decoding_results.append({\n",
    "        'word_1': pair[0],\n",
    "        'word_2': pair[1],\n",
    "        'neural_1_with_semantic_1': correct_correlation_match[0][0],\n",
    "        'neural_1_with_semantic_2': correct_correlation_match[0][1],\n",
    "        'neural_2_with_semantic_1': correct_correlation_match[1][0],\n",
    "        'neural_2_with_semantic_2': correct_correlation_match[1][1],\n",
    "        'correct_decoding': is_decoding_correct(correct_correlation_match)\n",
    "    })\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(decoding_results)\n",
    "\n",
    "# Output the DataFrame to a CSV file\n",
    "#results_df.to_csv('decoding_results_1_10_24.csv', index=False)\n",
    "results_df['correct_decoding'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472abd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
